{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4b12a39",
   "metadata": {},
   "source": [
    "# From Notebook to ModelOp Center:\n",
    "\n",
    "## Training, Evaluating, and Conforming a Model for Deployment\n",
    "In this notebook, we demonstrate the process of\n",
    "1. simple cleaning, feature engineering, and feature selection of a dataset,\n",
    "2. training a model,\n",
    "3. evaluating model performance,\n",
    "4. saving (pickling) the model (and other assets) for later use,\n",
    "5. and conforming the code into MOC standard\n",
    "\n",
    "More specifically, we will train a linear regression predictor on the Ames Housing Data dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47f9cf4",
   "metadata": {},
   "source": [
    "Let's load in the necessary libraries. We will be using `sklearn` to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48369c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas\n",
    "import numpy\n",
    "import copy\n",
    "import seaborn\n",
    "\n",
    "from sklearn import set_config\n",
    "from sklearn.linear_model import LassoCV, LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "#set_config(display='diagram')\n",
    "pandas.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48373273",
   "metadata": {},
   "source": [
    "**I - Data Cleaning, Feature Engineering, and Feature Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e35177",
   "metadata": {},
   "source": [
    "The **Ames Housing Data** dataset can be found [at this link](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data). Download the train dataset (we will be using it exclusively as those have all have an actual SalePrice value, our ground truth to use with the monitoring capabilities of ModelOp Center) and load it into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc10f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv('./house_price_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fe1dedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
       "       'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond',\n",
       "       'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl',\n",
       "       'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea',\n",
       "       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
       "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
       "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC',\n",
       "       'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
       "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
       "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu',\n",
       "       'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars',\n",
       "       'GarageArea', 'GarageQual', 'GarageCond', 'PavedDrive',\n",
       "       'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
       "       'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscFeature',\n",
       "       'MiscVal', 'MoSold', 'YrSold', 'SaleType', 'SaleCondition',\n",
       "       'SalePrice'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae678efc",
   "metadata": {},
   "source": [
    "Let's look at the top of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61cc06c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8938e8d",
   "metadata": {},
   "source": [
    "Before proceeding, let's split the original dataset into two sets: a **baseline** set which will be used as a reference set, and a **sample** set which will mimic input data to the model once the model is in use.\n",
    "\n",
    "We'l also prepare a `_scored` version of the dataframes for later use during our MOC monitoring phase. In that DataFrame, we'll mainly be using the `ground_truth`, which in our case is `SalePrice`, and `predictions` (later to be added) to compare drift, bias, and other metrics that we will want to monitor in the lifecycle of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20b844c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline, df_sample = train_test_split(df, train_size=0.8, random_state=777)\n",
    "\n",
    "df_baseline_scored = df_baseline.copy(deep=True)\n",
    "df_sample_scored = df_sample.copy(deep=True)\n",
    "\n",
    "df_baseline.to_json('df_baseline.json', orient='records', lines=True)\n",
    "df_sample.to_json('df_sample.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc82ecd1",
   "metadata": {},
   "source": [
    "Let's **clean up** the data. There are quite a few null values in the dataset and we'll fill them in with appropriate values. Note that these steps will also be necessary once we want to write code that conforms to ModelOp standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29a76a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features that contain 1 or more missing values:\n",
      "-  LotFrontage\n",
      "-  MasVnrArea\n",
      "-  GarageYrBlt\n"
     ]
    }
   ],
   "source": [
    "print('Numerical features that contain 1 or more missing values:')\n",
    "for col, dtype in df.dtypes.items():\n",
    "    if dtype != 'object' and df[col].isna().sum() > 0:\n",
    "        print('- ', col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e40dfc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imputing missing GarageYrBlt values with corresponding YrBlt values\n",
    "df_baseline.loc[:,'GarageYrBlt'] = df_baseline.loc[:, 'GarageYrBlt'].fillna(df_baseline['YearBuilt'])\n",
    "df_sample.loc[:,'GarageYrBlt'] = df_sample.loc[:, 'GarageYrBlt'].fillna(df_sample['YearBuilt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3ff905f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imputing `MasVnrArea` missing values with 0 and \n",
    "df_baseline.loc[:, 'MasVnrArea'] = df_baseline.loc[:, 'MasVnrArea'].fillna(0)\n",
    "df_sample.loc[:, 'MasVnrArea'] = df_sample.loc[:, 'MasVnrArea'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2718d513",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/royk/.local/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1117: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "# `LotFrontage` missing values with the median value of the neighborhood\n",
    "df_baseline['LotFrontage'] = df_baseline.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "df_baseline['LotFrontage'] = df_baseline['LotFrontage'].fillna(0)\n",
    "df_sample['LotFrontage'] = df_sample.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "df_sample['LotFrontage'] = df_sample['LotFrontage'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6486dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing the rest of the missing values in categorical features with 'None'\n",
    "for col in list(df.columns):\n",
    "    df_baseline.loc[:, col] = df_baseline.loc[:, col].fillna('None')\n",
    "    df_sample.loc[:, col] = df_sample.loc[:, col].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5846d9e",
   "metadata": {},
   "source": [
    "Next, let's write up some functions that will convert some categorical features into numerical features, then apply those functions to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "520b1435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Many columns use this generic scale\n",
    "generic = {\"Ex\": 4, \"Gd\": 3, \"TA\": 2, \"Fa\": 1, \"None\": 0}\n",
    "fireplace_quality = {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"None\": 0}\n",
    "garage_finish = {'Fin': 3, 'RFn': 2, 'Unf': 1, 'None': 0}\n",
    "fin_type = {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'None': 0}\n",
    "functional = {'Typ': 7, 'Min1': 6, 'Min2': 5, 'Mod': 4, 'Maj1': 3, 'Maj2': 2, 'Sev': 1, 'None': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4020cb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic conversions\n",
    "generic_columns = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'GarageQual', 'GarageCond', 'PoolQC']\n",
    "for col in generic_columns:\n",
    "    df_baseline.loc[:, col] = df_baseline[col].map(generic)\n",
    "    df_sample.loc[:, col] = df_sample[col].map(generic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddaa633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FireplaceQu convervsions\n",
    "df_baseline.loc[:, 'FireplaceQu'] = df_baseline['FireplaceQu'].map(fireplace_quality)\n",
    "df_sample.loc[:, 'FireplaceQu'] = df_sample['FireplaceQu'].map(fireplace_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73ddbb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FinType conversions\n",
    "fintype_columns = ['BsmtFinType1', 'BsmtFinType2']\n",
    "for col in fintype_columns:\n",
    "    df_baseline.loc[:, col] = df_baseline[col].map(fin_type)\n",
    "    df_sample.loc[:, col] = df_sample[col].map(fin_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "862dad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional conversion\n",
    "df_baseline.loc[:, 'Functional'] = df_baseline['Functional'].map(functional)\n",
    "df_sample.loc[:, 'Functional'] = df_sample['Functional'].map(functional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbe46a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GarageFinish conversion\n",
    "df_baseline.loc[:, 'GarageFinish'] = df_baseline['GarageFinish'].map(garage_finish)\n",
    "df_sample.loc[:, 'GarageFinish'] = df_sample['GarageFinish'].map(garage_finish)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec4e88f",
   "metadata": {},
   "source": [
    "We also have the `MSSubClass` numerical column which should be treated as a categorical column. We will convert this into an onject column to later be one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88fd1d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline['MSSubClass'] = df_baseline['MSSubClass'].astype(str)\n",
    "df_sample['MSSubClass'] = df_sample['MSSubClass'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53812589",
   "metadata": {},
   "source": [
    "Our data still contains non-predictive features, such as `Id` and `SalePrice`. We will set these aside and remove them the final list of predictive features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "698dc19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline_ids = df_baseline['Id']\n",
    "df_sample_ids = df_sample['Id']\n",
    "\n",
    "predictive_features = [\n",
    "    f for f in list(df.columns.values)\n",
    "    if f not in ['Id', 'SalePrice']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e9c0a1",
   "metadata": {},
   "source": [
    "Everything looks good; we'll proceed with model training. We need to specify **predictive** and **responsive** variables for each of the training and test sets. We'll set those by filtering the baseline and sample sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcd2b561",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_baseline[predictive_features]\n",
    "X_test = df_sample[predictive_features]\n",
    "\n",
    "y_train = df_baseline['SalePrice']\n",
    "y_test = df_sample['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154b0acd",
   "metadata": {},
   "source": [
    "Let's take a look at which columns contain muerical data and which contain categorical data. Some categorical features can easily be converted to numerical, as they might hold some order of value. Other categorical features will have to be one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b2bcdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = []\n",
    "categorical_features = []\n",
    "for i,j in zip(X_train.dtypes.index, X_train.dtypes.values):\n",
    "    if j=='object':\n",
    "        categorical_features.append(i)\n",
    "    else:\n",
    "        numerical_features.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89cd744",
   "metadata": {},
   "source": [
    "**Categorical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91d3ff2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'BsmtExposure', 'Heating', 'CentralAir', 'Electrical', 'GarageType', 'PavedDrive', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']\n"
     ]
    }
   ],
   "source": [
    "print(categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57338ba2",
   "metadata": {},
   "source": [
    "**Numerical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a09a7f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'HeatingQC', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC', 'MiscVal', 'MoSold', 'YrSold']\n"
     ]
    }
   ],
   "source": [
    "print(numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d2fc627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding with pandas.get_dummies()\n",
    "X_train = pandas.get_dummies(X_train, columns=categorical_features)\n",
    "X_test = pandas.get_dummies(X_test, columns=categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60abe0f",
   "metadata": {},
   "source": [
    "Let's do some **feature engineering**. While this portion of a data science project can be lengthy, we'll be doing some basic feature engineering in this example. A few ones that might be helpful are boolean features like `HasGarage` or `HasBsmt` and additive features like `TotalSF` or `TotalBathrooms`. We'll be adding `e` as a prefix to these columns to show that they have been engineered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45226955",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [X_train, X_test]:\n",
    "    #  computing total square footage as a new feature\n",
    "    data['eTotalSF'] = data['TotalBsmtSF'] + data['1stFlrSF'] + data['2ndFlrSF']\n",
    "\n",
    "    #  Computing total 'porch' square-footage as a new feature\n",
    "    data['eTotalPorchSF'] = (data['OpenPorchSF'] + data['3SsnPorch'] + data['EnclosedPorch'] + data['ScreenPorch'] + data['WoodDeckSF'])\n",
    "    \n",
    "    #  Computing total bathrooms as a new feature\n",
    "    data['eTotalBathrooms'] = (data['FullBath'] + (0.5 * data['HalfBath']) + data['BsmtFullBath'] + (0.5 * data['BsmtHalfBath']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d64cf6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineering some features into Booleans\n",
    "f = lambda x: bool(1) if x > 0 else bool(0)\n",
    "\n",
    "for data in [X_train, X_test]:\n",
    "    data['eHasPool'] = data['PoolArea'].apply(f)\n",
    "    data['eHasGarage'] = data['GarageArea'].apply(f)\n",
    "    data['eHasBsmt'] = data['TotalBsmtSF'].apply(f)\n",
    "    data['eHasFireplace'] = data['Fireplaces'].apply(f)\n",
    "    # feature to determine if a house had a remodeling\n",
    "    data['eHasRemodeling'] = data['YearRemodAdd'] - data['YearBuilt'] > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db67ae3",
   "metadata": {},
   "source": [
    "Let's engineer one more feature, `OverallQual_TotalSF`. This feature will be the multiplication of the `OverallQual` and `TotalSF` features. This specific combination of features, in fact, has the highest correlation to `SalePrice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a407a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [X_train, X_test]:\n",
    "    data['eOverallQual_TotalSF'] = data['OverallQual'] * data['eTotalSF']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fda9ed4",
   "metadata": {},
   "source": [
    "Let's move on to **feature selection**. We want our final model to only have a limited number of features, as too many features will cause the model to overfit, though too little will not allow our model to perform well. We'll take a look at the correlation of `SalePrice` to all other columns to determine which ones have the most predictive power, and choose 10 features to predict with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27012a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['SalePrice'] = df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb5e64f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Neighborhood_NridgHt', 0.4),\n",
       " ('BsmtFinSF1', 0.41),\n",
       " ('HeatingQC', 0.43),\n",
       " ('Fireplaces', 0.46),\n",
       " ('eHasFireplace', 0.47),\n",
       " ('MasVnrArea', 0.48),\n",
       " ('Foundation_PConc', 0.5),\n",
       " ('FireplaceQu', 0.51),\n",
       " ('YearRemodAdd', 0.52),\n",
       " ('TotRmsAbvGrd', 0.52),\n",
       " ('GarageYrBlt', 0.52),\n",
       " ('YearBuilt', 0.53),\n",
       " ('FullBath', 0.55),\n",
       " ('GarageFinish', 0.55),\n",
       " ('1stFlrSF', 0.6),\n",
       " ('TotalBsmtSF', 0.61),\n",
       " ('GarageArea', 0.62),\n",
       " ('BsmtQual', 0.63),\n",
       " ('eTotalBathrooms', 0.63),\n",
       " ('GarageCars', 0.64),\n",
       " ('KitchenQual', 0.66),\n",
       " ('ExterQual', 0.69),\n",
       " ('GrLivArea', 0.7),\n",
       " ('eTotalSF', 0.77),\n",
       " ('OverallQual', 0.78),\n",
       " ('eOverallQual_TotalSF', 0.84),\n",
       " ('SalePrice', 1.0)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strong_cols = [(col, round(corr, 2)) for col, corr in X_train.corr()['SalePrice'].items() if abs(corr) > 0.4]\n",
    "strong_cols.sort(key=lambda x:x[1])\n",
    "strong_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6ec3a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the final list of encoded columns\n",
    "train_encoded_columns = ['eOverallQual_TotalSF', 'OverallQual', 'eTotalSF', 'GrLivArea',\n",
    "                         'ExterQual', 'KitchenQual', 'GarageCars', 'eTotalBathrooms', 'BsmtQual', \n",
    "                         'GarageArea', 'TotalBsmtSF', 'GarageFinish', 'YearBuilt', 'eHasGarage', 'TotRmsAbvGrd', \n",
    "                         'eHasRemodeling', 'FireplaceQu', 'MasVnrArea', 'eHasFireplace', 'eHasBsmt']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f781b2ff",
   "metadata": {},
   "source": [
    "**II - Training the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aef4ec",
   "metadata": {},
   "source": [
    "Let's move on to training the model. Let's first restrict our feature space to only be that of the final list of columns. We'll be saving this list, as we'll need it when we deploy the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a896aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restricting X_train and X_test columns to only be final list of columns\n",
    "X_train = X_train[train_encoded_columns]\n",
    "X_test = X_test[train_encoded_columns]\n",
    "\n",
    "# Saving the final list of encoded columns\n",
    "pickle.dump(train_encoded_columns, open('train_encoded_columns.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34076164",
   "metadata": {},
   "source": [
    "Another thing we can do to make our model a bit more performant, as well as explainable, is to standardize the features. This will allow us to interpret the weights on each feature directly against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91ac863d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eOverallQual_TotalSF      int64\n",
       "OverallQual               int64\n",
       "eTotalSF                  int64\n",
       "GrLivArea                 int64\n",
       "ExterQual                 int64\n",
       "KitchenQual               int64\n",
       "GarageCars                int64\n",
       "eTotalBathrooms         float64\n",
       "BsmtQual                  int64\n",
       "GarageArea                int64\n",
       "TotalBsmtSF               int64\n",
       "GarageFinish              int64\n",
       "YearBuilt                 int64\n",
       "eHasGarage                 bool\n",
       "TotRmsAbvGrd              int64\n",
       "eHasRemodeling             bool\n",
       "FireplaceQu               int64\n",
       "MasVnrArea              float64\n",
       "eHasFireplace              bool\n",
       "eHasBsmt                   bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d087cb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_ss = ss.fit_transform(numpy.array(X_train))\n",
    "X_test_ss = ss.transform(numpy.array(X_test))\n",
    "pickle.dump(ss, open('standard_scaler.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7fd828",
   "metadata": {},
   "source": [
    "One last thing we can do is to apply a logarithm to `SalePrice`. If we look at the distribution of values for `SalePrice`, we can notice that there is a right skew, with values at the top of the distribution quite distant from the average value of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5aaeb86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a48128b",
   "metadata": {},
   "source": [
    "Applying a logarithm will allow the distribution to be centralized, allowing our model that will be trained to be more performant. We'll specifically use the `numpy.log1p()` function in case that there are values are 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ef451f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_log = numpy.log1p(y_train)\n",
    "y_test_log = numpy.log1p(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62e94ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train_log.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c9da4b",
   "metadata": {},
   "source": [
    "The distribution is now roughly normalized, and the model should be able to predict better. One thing we need to keep in mind, however, is that if we want predictions, we will have to inverse the logarithm on the outputs of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80e4a37",
   "metadata": {},
   "source": [
    "We will train a **Lasso** linear regression model. Let's fit the model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a0eec68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8167504671863937"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the cross-validation score with 5 (default) folds, showing how the model should generally perform, irrespective to how the data was split\n",
    "cross_val_score(LassoCV(max_iter=5000), X_train_ss, y_train_log).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fff85016",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=None, copy_X=True, cv=None, eps=0.001, fit_intercept=True,\n",
       "        max_iter=5000, n_alphas=100, n_jobs=None, normalize=False,\n",
       "        positive=False, precompute='auto', random_state=None,\n",
       "        selection='cyclic', tol=0.0001, verbose=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = LassoCV(max_iter=5000)\n",
    "lasso.fit(X_train_ss, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c8507ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8430704847122994"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.score(X_train_ss, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f03074ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8580636796558804"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.score(X_test_ss, y_test_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7acce9",
   "metadata": {},
   "source": [
    "**III - Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55859d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Before saving our trained model for further use, let's take a look at some performance metrics. We will evaluate the model on both the training and test sets; we want to see a stable performance between the two.  \n",
    "\n",
    "For repeatability, let's define a function which computes multiple metrics at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b55521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y, y_preds):\n",
    "    \"\"\"\n",
    "    A function to evaluate a regression model.\n",
    "    \n",
    "    param: y: true (ground truth) values\n",
    "    param: y_preds: predicted values (as predicted by model)\n",
    "    \n",
    "    return: multiple regression performance metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    return {\n",
    "        'Mean Absolute Error' : round(mean_absolute_error(y, y_preds), 2),\n",
    "        'Root Mean Squared Error' : round(mean_squared_error(y, y_preds) ** 0.5, 2),\n",
    "        'R2 Score' : round(r2_score(y, y_preds), 3)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab199f3",
   "metadata": {},
   "source": [
    "Let's compute predictions on both training and test sets. Remember, we need to apply an inverse log to convert the outputs into the same units as our inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8da57825",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = numpy.round(numpy.expm1(lasso.predict(X_train_ss)), 2)\n",
    "y_test_preds = numpy.round(numpy.expm1(lasso.predict(X_test_ss)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "277d73eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "performance_df = pandas.DataFrame(\n",
    "    data=[{}],\n",
    "    columns=['Mean Absolute Error', 'Root Mean Squared Error', 'R2 Score'],\n",
    "    index=['Training Set', 'Test Set']\n",
    ")\n",
    "performance_df.loc['Training Set', :] = compute_metrics(y_train, y_train_preds)\n",
    "performance_df.loc['Test Set', :] = compute_metrics(y_test, y_test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df030647",
   "metadata": {},
   "source": [
    "Let's look at how our model performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e98572dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>R2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training Set</th>\n",
       "      <td>20914.02</td>\n",
       "      <td>36422.12</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Set</th>\n",
       "      <td>16715.31</td>\n",
       "      <td>23450.18</td>\n",
       "      <td>0.885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mean Absolute Error  Root Mean Squared Error  R2 Score\n",
       "Training Set             20914.02                 36422.12     0.801\n",
       "Test Set                 16715.31                 23450.18     0.885"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b39275",
   "metadata": {},
   "source": [
    "There is a slight difference in performance between the training set and the test set on some of the metrics. This could have come from the way that the data was split, or other issues. Further model improvements are needed to achieve more accurate inferences. For now, we will contend with this model and use it to produce new predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8479b69",
   "metadata": {},
   "source": [
    "**IV - Saving and Loading the Trained Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c551fd5",
   "metadata": {},
   "source": [
    "Now that the model is **trained** and **evaluated**, we save it in a binary format. It will later be loaded and used to make new predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f79390c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lasso, open('lasso.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249e8a29",
   "metadata": {},
   "source": [
    "The model is reloaded on-demands as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8cfbbbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_loaded = pickle.load(open('lasso.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7003ebca",
   "metadata": {},
   "source": [
    "Predictions can be produced on-demand by calling the `predict()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc88ee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_preds = lasso_loaded.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c024be03",
   "metadata": {},
   "source": [
    "Before heading into the next section, let's append our predictions to our `_scored` DataFrames and save them. Once again, these data sets will be used mainly for monitoring purposes. Note that the features on these datasets will be the final list of features used that the model expects during prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "014eaf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = train_encoded_columns.copy()\n",
    "\n",
    "all_cols.append('SalePrice')\n",
    "\n",
    "cols_reordered = ['Id', 'prediction', 'SalePrice']\n",
    "cols_reordered.extend(train_encoded_columns)\n",
    "\n",
    "X_train['SalePrice'] = y_train\n",
    "X_test['SalePrice'] = y_test\n",
    "\n",
    "df_baseline_scored = X_train[all_cols]\n",
    "df_baseline_scored['prediction'] = y_train_preds\n",
    "df_baseline_scored['Id'] = df_baseline_ids\n",
    "df_baseline_scored = df_baseline_scored[cols_reordered]\n",
    "\n",
    "df_sample_scored = X_test[all_cols]\n",
    "df_sample_scored['prediction'] = y_test_preds\n",
    "df_sample_scored['Id'] = df_sample_ids\n",
    "df_sample_scored = df_sample_scored[cols_reordered]\n",
    "\n",
    "df_baseline_scored.to_json('df_baseline_scored.json', orient='records', lines=True)\n",
    "df_sample_scored.to_json('df_sample_scored.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6f0c7a",
   "metadata": {},
   "source": [
    "**V - Conforming Model Code to MOC Requirements**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0141dc",
   "metadata": {},
   "source": [
    "Conformance is best demonstrated through example. Let's look at the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9316a64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelop.slot.0: in-use\n",
    "# modelop.slot.1: in-use\n",
    "\n",
    "\n",
    "import pandas\n",
    "import pickle\n",
    "import numpy\n",
    "import logging\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "\n",
    "\n",
    "# modelop.init\n",
    "def begin():\n",
    "    \n",
    "    global lasso_model\n",
    "    global standard_scaler\n",
    "    global train_encoded_columns\n",
    "\n",
    "    # Load pickled Lasso linear regression model\n",
    "    lasso_model = pickle.load(open(\"lasso.pickle\", \"rb\"))\n",
    "    # Load pickled standard scaler\n",
    "    standard_scaler = pickle.load(open(\"standard_scaler.pickle\", \"rb\"))\n",
    "    # Load train_encoded_columns\n",
    "    train_encoded_columns = pickle.load(open(\"train_encoded_columns.pickle\", \"rb\"))\n",
    "\n",
    "    logger.info(\n",
    "        \"'lasso.pickle', 'standard_scaler.pickle', and 'train_encoded_columns.pickle' files loaded to respective variables\"\n",
    "    )\n",
    "\n",
    "\n",
    "# modelop.score\n",
    "def action(data):\n",
    "    \n",
    "    # Turning data into a dataframe\n",
    "    logger.info(\"Loading input record into a pandas.DataFrame\")\n",
    "    input_data = pandas.DataFrame([data])\n",
    "\n",
    "    # Set aside ground truth to later re-append to dataframe\n",
    "    ground_truth = input_data[\"SalePrice\"]\n",
    "\n",
    "    # Dictionaries to convert values in certain columns\n",
    "    generic = {\"Ex\": 4, \"Gd\": 3, \"TA\": 2, \"Fa\": 1, \"None\": 0}\n",
    "    fireplace_quality = {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"None\": 0}\n",
    "    garage_finish = {\"Fin\": 3, \"RFn\": 2, \"Unf\": 1, \"None\": 0}\n",
    "\n",
    "    # Imputations\n",
    "    logger.info(\"Conforming input dataset to be model-ready\")\n",
    "    input_data.loc[:, \"GarageYrBlt\"] = input_data.loc[:, \"GarageYrBlt\"].fillna(input_data[\"YearBuilt\"])\n",
    "    for col in [\"GarageFinish\", \"BsmtQual\", \"FireplaceQu\"]:\n",
    "        input_data.loc[:, col] = input_data.loc[:, col].fillna(\"None\")\n",
    "    # The rest of NaNs will be filled with 0s - end model only uses numerical features\n",
    "    for col in input_data.columns:\n",
    "        input_data[col] = input_data[col].fillna(0)\n",
    "\n",
    "    # Converting categorical values from certain features into numerical\n",
    "    for col in [\"BsmtQual\", \"KitchenQual\", \"ExterQual\"]:\n",
    "        input_data.loc[:, col] = input_data[col].map(generic)\n",
    "    input_data.loc[:, \"GarageFinish\"] = input_data[\"GarageFinish\"].map(garage_finish)\n",
    "    input_data.loc[:, \"FireplaceQu\"] = input_data[\"FireplaceQu\"].map(fireplace_quality)\n",
    "\n",
    "    # Feature engineering\n",
    "    f = lambda x: bool(1) if x > 0 else bool(0)\n",
    "    input_data[\"eHasPool\"] = input_data[\"PoolArea\"].apply(f)\n",
    "    input_data[\"eHasGarage\"] = input_data[\"GarageArea\"].apply(f)\n",
    "    input_data[\"eHasBsmt\"] = input_data[\"TotalBsmtSF\"].apply(f)\n",
    "    input_data[\"eHasFireplace\"] = input_data[\"Fireplaces\"].apply(f)\n",
    "    input_data[\"eHasRemodeling\"] = input_data[\"YearRemodAdd\"] - input_data[\"YearBuilt\"] > 0\n",
    "    input_data[\"eTotalSF\"] = input_data[\"TotalBsmtSF\"] + input_data[\"1stFlrSF\"] + input_data[\"2ndFlrSF\"]\n",
    "    input_data[\"eTotalBathrooms\"] = (\n",
    "        input_data[\"FullBath\"]\n",
    "        + (0.5 * input_data[\"HalfBath\"])\n",
    "        + input_data[\"BsmtFullBath\"]\n",
    "        + (0.5 * input_data[\"BsmtHalfBath\"])\n",
    "    )\n",
    "    input_data[\"eOverallQual_TotalSF\"] = input_data[\"OverallQual\"] * input_data[\"eTotalSF\"]\n",
    "\n",
    "    # Limiting features to just the ones the model needs\n",
    "    logger.info(\"Selecting columns that model is expecting\")\n",
    "    input_data = input_data[train_encoded_columns]\n",
    "\n",
    "    # Scale inputs\n",
    "    logger.info(\"Scaling data with pickled standard scaler\")\n",
    "    df_ss = standard_scaler.transform(input_data)\n",
    "\n",
    "    # generate predictions and rename columns\n",
    "    logger.info(\"Generating predictions with the model and appending onto DataFrame\")\n",
    "    input_data.loc[:, \"prediction\"] = numpy.round(numpy.expm1(lasso_model.predict(df_ss)), 2)\n",
    "    input_data.loc[:, \"SalePrice\"] = ground_truth\n",
    "\n",
    "    # MOC expects the action function to be a \"yield\" function\n",
    "    yield input_data.to_dict(orient=\"records\")\n",
    "\n",
    "\n",
    "# modelop.metrics\n",
    "def metrics(metrics_data):\n",
    "    \n",
    "    logger.info(\"metrics_data is of shape: %s\", metrics_data.shape)\n",
    "\n",
    "    logger.info(\"Grabbing relevant columns to calculate metrics\")\n",
    "    y = metrics_data[\"SalePrice\"]\n",
    "    y_preds = metrics_data[\"prediction\"]\n",
    "\n",
    "    logger.info(\"Computing MAE, RMSE, R2 scores\")\n",
    "    output_metrics = {\n",
    "        \"MAE\": mean_absolute_error(y, y_preds),\n",
    "        \"RMSE\": mean_squared_error(y, y_preds) ** 0.5,\n",
    "        \"R2\": r2_score(y, y_preds),\n",
    "    }\n",
    "    \n",
    "    logger.info(\"Metrics job complete!\")\n",
    "\n",
    "    # MOC expects the metrics function to be a \"yield\" function\n",
    "    yield output_metrics\n",
    "\n",
    "\n",
    "# modelop.train\n",
    "def train(training_data):\n",
    "    \n",
    "    logger.info(\"training_data is of shape: %s\", training_data.shape)\n",
    "    \n",
    "    # Set aside ground truth to later re-append to dataframe\n",
    "    y_train = training_data[\"SalePrice\"]\n",
    "\n",
    "    # Dictionaries to convert values in certain columns\n",
    "    generic = {\"Ex\": 4, \"Gd\": 3, \"TA\": 2, \"Fa\": 1, \"None\": 0}\n",
    "    fireplace_quality = {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"None\": 0}\n",
    "    garage_finish = {\"Fin\": 3, \"RFn\": 2, \"Unf\": 1, \"None\": 0}\n",
    "\n",
    "    # Imputations\n",
    "    logger.info(\"Imputing Nulls\")\n",
    "    training_data.loc[:, \"GarageYrBlt\"] = training_data.loc[:, \"GarageYrBlt\"].fillna(training_data[\"YearBuilt\"])\n",
    "    for col in [\"GarageFinish\", \"BsmtQual\", \"FireplaceQu\"]:\n",
    "        training_data.loc[:, col] = training_data.loc[:, col].fillna(\"None\")\n",
    "    # The rest of NaNs will be filled with 0s - end model only uses numerical features\n",
    "    for col in training_data.columns:\n",
    "        training_data[col] = training_data[col].fillna(0)\n",
    "\n",
    "    # Converting categorical values from certain features into numerical\n",
    "    logger.info(\"Converting categorical values to numerical values\")\n",
    "    for col in [\"BsmtQual\", \"KitchenQual\", \"ExterQual\"]:\n",
    "        training_data.loc[:, col] = training_data[col].map(generic)\n",
    "    training_data.loc[:, \"GarageFinish\"] = training_data[\"GarageFinish\"].map(garage_finish)\n",
    "    training_data.loc[:, \"FireplaceQu\"] = training_data[\"FireplaceQu\"].map(fireplace_quality)\n",
    "\n",
    "    # Feature engineering\n",
    "    logger.info(\"Creating new features with feature engineering\")\n",
    "    f = lambda x: 1 if x > 0 else 0\n",
    "    training_data[\"eHasPool\"] = training_data[\"PoolArea\"].apply(f)\n",
    "    training_data[\"eHasGarage\"] = training_data[\"GarageArea\"].apply(f)\n",
    "    training_data[\"eHasBsmt\"] = training_data[\"TotalBsmtSF\"].apply(f)\n",
    "    training_data[\"eHasFireplace\"] = training_data[\"Fireplaces\"].apply(f)\n",
    "    training_data[\"eHasRemodeling\"] = (training_data[\"YearRemodAdd\"] - training_data[\"YearBuilt\"] > 0).astype(int)\n",
    "    training_data[\"eTotalSF\"] = training_data[\"TotalBsmtSF\"] + training_data[\"1stFlrSF\"] + training_data[\"2ndFlrSF\"]\n",
    "    training_data[\"eTotalBathrooms\"] = (\n",
    "        training_data[\"FullBath\"]\n",
    "        + (0.5 * training_data[\"HalfBath\"])\n",
    "        + training_data[\"BsmtFullBath\"]\n",
    "        + (0.5 * training_data[\"BsmtHalfBath\"])\n",
    "    )\n",
    "    training_data[\"eOverallQual_TotalSF\"] = training_data[\"OverallQual\"] * training_data[\"eTotalSF\"]\n",
    "\n",
    "    # Final list of encoded columns\n",
    "    train_encoded_columns = [\n",
    "        \"eOverallQual_TotalSF\",\n",
    "        \"OverallQual\",\n",
    "        \"eTotalSF\",\n",
    "        \"GrLivArea\",\n",
    "        \"ExterQual\",\n",
    "        \"KitchenQual\",\n",
    "        \"GarageCars\",\n",
    "        \"eTotalBathrooms\",\n",
    "        \"BsmtQual\",\n",
    "        \"GarageArea\",\n",
    "        \"TotalBsmtSF\",\n",
    "        \"GarageFinish\",\n",
    "        \"YearBuilt\",\n",
    "        \"eHasGarage\",\n",
    "        \"TotRmsAbvGrd\",\n",
    "        \"eHasRemodeling\",\n",
    "        \"FireplaceQu\",\n",
    "        \"MasVnrArea\",\n",
    "        \"eHasFireplace\",\n",
    "        \"eHasBsmt\",\n",
    "    ]\n",
    "\n",
    "    # Saving the final list of encoded columns\n",
    "    logger.info(\"Pickling final list of columns for model to predict with\")\n",
    "    \n",
    "    # Pickle file should be written to outputDir/    \n",
    "    with open(\"outputDir/train_encoded_columns.pickle\", \"wb\") as columns_file:\n",
    "        pickle.dump(train_encoded_columns, columns_file)\n",
    "\n",
    "    # Choosing only the final list of encoded columns\n",
    "    X_train = training_data[train_encoded_columns]\n",
    "    \n",
    "    # Standard scale data and pickle scaler\n",
    "    standard_scaler = StandardScaler()\n",
    "    X_train_ss = standard_scaler.fit_transform(numpy.array(X_train))\n",
    "    logger.info(\"Pickling trained standard scaler object\")\n",
    "    \n",
    "    # Pickle file should be written to outputDir/    \n",
    "    with open(\"outputDir/standard_scaler.pickle\", \"wb\") as scaler_file:\n",
    "        pickle.dump(standard_scaler, scaler_file)\n",
    "    \n",
    "    # Apply log to distribution of y-values\n",
    "    y_train_log = numpy.log1p(y_train)\n",
    "\n",
    "    # Train and pickle model artifact\n",
    "    logger.info(\"Fitting LASSO model\")\n",
    "    lasso = LassoCV(max_iter=1000)\n",
    "    lasso.fit(X_train_ss, y_train_log)\n",
    "    logger.info(\"Pickling trained LASSO model\")\n",
    "\n",
    "    # Pickle file should be written to outputDir/   \n",
    "    with open(\"outputDir/lasso.pickle\", \"wb\") as lasso_file:\n",
    "        pickle.dump(lasso, lasso_file)\n",
    "\n",
    "    logger.info(\"Training job complete!\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aa168c",
   "metadata": {},
   "source": [
    "There are five main sections that are standard to almost any model in MOC:\n",
    "1. Library imports\n",
    "2. `init` function\n",
    "3. `score` function\n",
    "4. `metrics` function\n",
    "5. `train` function\n",
    "\n",
    "**Library** imports are always at the top. We don't need to include all libraries that we used for training and model evaluation. We just need the libraries for processing and scoring.\n",
    "\n",
    "The **`init`** function runs once per deployment, and is used to load and persist into memory any variable that needs to be accessed at scoring time. For example, the init function is where we load the saved model binary, scalers, and any other dependencies. We make the variables global so they can be accessed from the scoring function. In our example, we also included the `train_encoded_columns` as this information will not change per prediction and only needs to be instantiated once.\n",
    "\n",
    "The **`score`** function is the function that runs anytime we make a scoring (prediction) request. This is where we put our prediction code. We have to remember to include any steps that were not captured by the pipeline, such as feature engineering or re-encoding.\n",
    "\n",
    "The **`metrics`** functions is where model evaluation is carried out. In our example, this is the place where we compute regression metrics.\n",
    "\n",
    "The **`train`** function is where model training is carried out. This function does not have to `return` or `yield`, and can instead simply `pass`. Any trained artifact should be written - for example as a pickle file) - to `outputDir/`. ModelOp Center will read the contents of this directory once the training job is complete, and make the contents available as job outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d2d98b",
   "metadata": {},
   "source": [
    "Let us test our source code to see if we missed anything. We will load input data and scored input data to test both the scoring and metrics functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9dd09179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for the action function (scoring)\n",
    "scoring_sample = pandas.read_json('df_baseline.json', orient='records', lines=True)\n",
    "\n",
    "# these are for the metrics function\n",
    "metrics_baseline_input = pandas.read_json('df_baseline_scored.json', orient='records', lines=True)\n",
    "metrics_sample_input = pandas.read_json('df_sample_scored.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a17813",
   "metadata": {},
   "source": [
    "Let's check that the **`init`** function can load the trained model binary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f2d42658",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:'lasso.pickle', 'standard_scaler.pickle', and 'train_encoded_columns.pickle' files loaded to respective variables\n"
     ]
    }
   ],
   "source": [
    "begin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2cb51f",
   "metadata": {},
   "source": [
    "No errors from the **`init`** function. Let's make a call to the **`score`** function on input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f6852fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading input record into a pandas.DataFrame\n",
      "INFO:__main__:Conforming input dataset to be model-ready\n",
      "INFO:__main__:Selecting columns that model is expecting\n",
      "INFO:__main__:Scaling data with pickled standard scaler\n",
      "INFO:__main__:Generating predictions with the model and appending onto DataFrame\n"
     ]
    }
   ],
   "source": [
    "scores = pandas.DataFrame(\n",
    "    next(\n",
    "        action(scoring_sample.iloc[0])\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "196d3b26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eOverallQual_TotalSF</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>eTotalSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>eTotalBathrooms</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>...</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>eHasGarage</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>eHasRemodeling</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>eHasFireplace</th>\n",
       "      <th>eHasBsmt</th>\n",
       "      <th>prediction</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18192</td>\n",
       "      <td>6</td>\n",
       "      <td>3032</td>\n",
       "      <td>1516</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>472</td>\n",
       "      <td>...</td>\n",
       "      <td>1964</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>156491.21</td>\n",
       "      <td>167000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   eOverallQual_TotalSF  OverallQual  eTotalSF  GrLivArea  ExterQual  \\\n",
       "0                 18192            6      3032       1516          2   \n",
       "\n",
       "   KitchenQual  GarageCars  eTotalBathrooms  BsmtQual  GarageArea  ...  \\\n",
       "0            2           2              1.5         2         472  ...   \n",
       "\n",
       "   YearBuilt  eHasGarage  TotRmsAbvGrd  eHasRemodeling  FireplaceQu  \\\n",
       "0       1964        True             6           False            0   \n",
       "\n",
       "   MasVnrArea  eHasFireplace  eHasBsmt  prediction  SalePrice  \n",
       "0       180.0          False      True   156491.21     167000  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6759d94",
   "metadata": {},
   "source": [
    "We scores! Finally, let's call the **`metrics`** function on scored data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5647528b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:metrics_data is of shape: (1168, 23)\n",
      "INFO:__main__:Grabbing relevant columns to calculate metrics\n",
      "INFO:__main__:Computing MAE, RMSE, R2 scores\n",
      "INFO:__main__:Metrics job complete!\n",
      "INFO:__main__:metrics_data is of shape: (292, 23)\n",
      "INFO:__main__:Grabbing relevant columns to calculate metrics\n",
      "INFO:__main__:Computing MAE, RMSE, R2 scores\n",
      "INFO:__main__:Metrics job complete!\n"
     ]
    }
   ],
   "source": [
    "metrics_compare = pandas.DataFrame(\n",
    "    [\n",
    "        next(\n",
    "            metrics(metrics_baseline_input)\n",
    "        ), \n",
    "        next(\n",
    "            metrics(metrics_sample_input)\n",
    "        )\n",
    "    ],\n",
    "    index=['baseline', 'sample']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4def1e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>20914.018767</td>\n",
       "      <td>36422.119215</td>\n",
       "      <td>0.801362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <td>16715.310240</td>\n",
       "      <td>23450.183792</td>\n",
       "      <td>0.885231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   MAE          RMSE        R2\n",
       "baseline  20914.018767  36422.119215  0.801362\n",
       "sample    16715.310240  23450.183792  0.885231"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_compare"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1bc0af681b6debbd76b10de7ba3014cd62e1e3ee55e8e9a892bbbe23fd8d618c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
